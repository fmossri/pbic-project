# Pipeline RAG de IngestÃ£o de PDFs

Sistema para processamento de documentos PDF, geraÃ§Ã£o de embeddings, busca semÃ¢ntica e obtenÃ§Ã£o de respostas contextuais atravÃ©s de modelos de linguagem.

## VisÃ£o Geral

Este sistema processa documentos PDF, extrai texto, divide em chunks, gera embeddings e responde perguntas utilizando busca por similaridade e recuperaÃ§Ã£o de documentos. O sistema Ã© projetado para ser escalÃ¡vel, confiÃ¡vel e fÃ¡cil de usar, constituindo uma soluÃ§Ã£o sequencial simples "naive RAG"

### Funcionalidades Principais

- Processamento de documentos PDF
- DetecÃ§Ã£o de duplicatas via hash MD5
- DivisÃ£o de texto em chunks
- GeraÃ§Ã£o de embeddings
- NormalizaÃ§Ã£o de texto
- Armazenamento de embeddings com FAISS
- Armazenamento de chunks e metadados com SQLite
- Busca por similaridade e recuperaÃ§Ã£o de chunks relevantes
- IntegraÃ§Ã£o com modelos de linguagem via API da Hugging Face

## Estrutura do Projeto

```
/root
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_ingestion/
â”‚   â”‚   â”œâ”€â”€ document_processor.py
â”‚   â”‚   â”œâ”€â”€ text_chunker.py
â”‚   â”‚   â””â”€â”€ data_ingestion_orchestrator.py
â”‚   â”œâ”€â”€ query_processing/
â”‚   â”‚   â”œâ”€â”€ query_orchestrator.py
â”‚   â”‚   â””â”€â”€ hugging_face_manager.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ embedding_generator.py
â”‚   â”‚   â”œâ”€â”€ text_normalizer.py
â”‚   â”‚   â”œâ”€â”€ sqlite_manager.py
â”‚   â”‚   â””â”€â”€ faiss_manager.py
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ document_file.py
â”‚       â”œâ”€â”€ chunk.py
â”‚       â””â”€â”€ embedding.py
â”œâ”€â”€ storage/
â”‚   â””â”€â”€ domains/
â”‚       â”œâ”€â”€ public/
â”‚       â”‚   â”œâ”€â”€ public.db
â”‚       â”‚   â””â”€â”€ vector_store/
â”‚       â”‚       â””â”€â”€ index.faiss
â”‚       â””â”€â”€ test_domain/
â”‚           â”œâ”€â”€ test.db
â”‚           â””â”€â”€ vector_store/
â”‚               â””â”€â”€ test.faiss
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ data_ingestion/
â”‚   â”‚   â”œâ”€â”€ test_document_processor.py
â”‚   â”‚   â”œâ”€â”€ test_data_ingestion_orchestrator.py
â”‚   â”‚   â”œâ”€â”€ test_text_chunker.py
â”‚   â”‚   â””â”€â”€ test_docs/
â”‚   â”‚       â””â”€â”€ generate_test_pdfs.py
â”‚   â”œâ”€â”€ query_processing/
â”‚   â”‚   â”œâ”€â”€ test_query_orchestrator.py
â”‚   â”‚   â””â”€â”€ test_hugging_face_manager.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ test_embedding_generator.py
â”‚       â”œâ”€â”€ test_text_normalizer.py
â”‚       â”œâ”€â”€ test_sqlite_manager.py
â”‚       â””â”€â”€ test_faiss_manager.py
â”œâ”€â”€ main.py
â””â”€â”€ README.md
```

## Componentes Principais

### Pipeline de IngestÃ£o de Dados

#### 1. DataIngestionOrchestrator
- Coordena todo o fluxo de processamento de ingestÃ£o
- Efetua controle de duplicatas via hash MD5
- Controla transaÃ§Ãµes para garantir a integridade dos dados
- Processa diretÃ³rios inteiros de PDFs
- Interfaces:
  * `process_directory`: Executa a pipeline de ingestÃ£o
  * `list_pdf_files`: Lista os pdfs de um diretÃ³rio

#### 2. DocumentProcessor
- Processa arquivos PDF e extrai texto
- Calcula hash MD5 para detecÃ§Ã£o de duplicatas
- Trata erros de PDF invÃ¡lido com propagaÃ§Ã£o adequada
- Interfaces:
  * `process_document`: Extrai o texto e calcula o hash de um documento PDF

#### 3. TextChunker
- Divide texto em chunks recursivos mantendo coerÃªncia
- Utiliza RecursiveCharacterTextSplitter para divisÃ£o por marcadores de quebra natural
- Preserva estrutura do documento original nos chunks
- Interfaces:
  * `chunk_text`: DivisÃ£o principal do texto

### Pipeline de Consulta

#### 1. QueryOrchestrator
- Coordena todo o processo de consulta
- Converte consultas em embeddings
- Recupera chunks relevantes via busca vetorial
- Prepara contexto para modelos de linguagem
- Interfaces:
  * `query_llm`: Executa a pipeline de recuperaÃ§Ã£o e consulta

#### 2. HuggingFaceManager
- Interface com a API de InferÃªncia do Hugging Face
- Suporta diferentes modelos de linguagem (no momento zephyr-7b-beta)
- ParÃ¢metros de geraÃ§Ã£o configurÃ¡veis (temperatura, top_p, etc.)
- Interfaces:
  * `generate_answer`: Consulta o LLM e retorna a resposta

### Componentes Compartilhados

#### 1. TextNormalizer
- Realiza normalizaÃ§Ã£o Unicode (NFKC)
- Normaliza espaÃ§os preservando estrutura
- Normaliza case para minÃºsculas
- Interfaces:
  * `normalize`: Pipeline completo de normalizaÃ§Ã£o

#### 2. EmbeddingGenerator
- Gera representaÃ§Ãµes vetoriais para texto
- Realiza processamento em lote para melhor performance
- IntegraÃ§Ã£o com sentence-transformers
- Interfaces:
  * `generate_embeddings`: Gera embeddings a partir do texto fornecido

#### 3. SQLiteManager
- Gerencia todas as operaÃ§Ãµes de banco de dados
- InicializaÃ§Ã£o de schema e controle de versÃ£o
- Controle de transaÃ§Ãµes (commit/rollback)
- Armazenamento de documentos, chunks e metadados de embeddings
- Armazena os arquivos .db em `storage/domains/{domain_name}/`
- Interfaces:
  * `insert_document_file`: Insere os metadados dos documentos no banco de dados
  * `insert_chunks`: Insere os chunks de texto no banco de dados
  * `insert_embeddings`: Insere os metadados dos embeddings
  * `get_embeddings_chunks`: Recupera os chunks pelos Ã­ndices FAISS de seus embeddings

#### 4. FaissManager
- Gerencia Ã­ndices FAISS para busca por similaridade
- Cria, carrega e consulta Ã­ndices
- Adiciona os embeddings ao Ã­ndice FAISS
- Armazena os arquivos .faiss em `storage/domains/{domain_name}/vector_store/`
- Realiza busca por similaridade
- Interfaces:
  * `add_embeddings`: Adiciona embeddings ao Ã­ndice
  * `search_faiss_index`: Realiza busca por similaridade

### Modelos de Dados

#### 1. DocumentFile
- Representa um documento PDF com metadados
- Rastreia caminho, hash e contagem de pÃ¡ginas

#### 2. Chunk
- Representa um chunk de texto com informaÃ§Ãµes de posiÃ§Ã£o
- ReferÃªncia para o documento pai

#### 3. Embedding
- Representa um embedding vetorial
- Metadados para rastreamento no Ã­ndice FAISS
- ReferÃªncia para o chunk pai

## Requisitos

- Python 3.10+
- DependÃªncias principais:
  * pypdf 5.4.0
  * sentence-transformers 3.4.1
  * faiss-cpu 1.10.0
  * huggingface-hub 0.29.3
  * langchain 0.3.21
  * langchain-text-splitters 0.3.7
  * SQLAlchemy 2.0.39
  * pytest 8.3.5
  * python-dotenv 1.0.1

## InstalaÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/fmossri/pbic-project.git
cd pbic-project
```

2. Crie e ative um ambiente virtual:
```bash
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# ou
.venv\Scripts\activate  # Windows
```

3. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

4. Crie um token de acesso com permissÃµes de leitura na Hugging Face;

5. Crie um arquivo .env e adicione a seguinte variÃ¡vel de ambiente:
```
HUGGINGFACE_API_TOKEN="seu token de acesso"
```

## Uso

** main.py --help

** Opcional: adicionar --debug ao final traz mais informaÃ§Ãµes ao console e aos arquivos de log.

### Processando PDFs e Gerando Embeddings

```bash
python main.py -i caminho/do/diretÃ³rio
```

### Realizando Consultas

```bash
python main.py -q "Sua pergunta aqui"
```

### Executando Testes

```bash
python -m pytest -vv
```

## Estado Atual do Desenvolvimento

### Componentes ConcluÃ­dos âœ…

- Pipeline completo de ingestÃ£o de PDF
- Processamento de texto e chunking semÃ¢ntico
- GeraÃ§Ã£o de embeddings e normalizaÃ§Ã£o de texto
- Armazenamento SQLite com gerenciamento de transaÃ§Ãµes
- Armazenamento FAISS para vetores
- Sistema de consulta e recuperaÃ§Ã£o
- IntegraÃ§Ã£o com Hugging Face para geraÃ§Ã£o de respostas
- Testes unitÃ¡rios e de integraÃ§Ã£o
- Logger

### Em Desenvolvimento ðŸ”„

- LÃ³gica de criaÃ§Ã£o de domÃ­nios
- SeparaÃ§Ã£o de documentos ingeridos por domÃ­nio (.db e .faiss independentes)
- Sistema de seleÃ§Ã£o de domÃ­nios para geraÃ§Ã£o de respostas usando busca por similaridade
- Sistema de configuraÃ§Ã£o
- Interface de usuÃ¡rio
- **API RESTful
- **Funcionalidades avanÃ§adas de busca

## PrÃ³ximos Passos PossÃ­veis

1. **Aprimoramento do Sistema de Consulta**
   - OtimizaÃ§Ã£o de prompts
   - ExpansÃ£o de consultas usando sinÃ´nimos
   - Re-ranqueamento dos chunks recuperados
   - AtribuiÃ§Ã£o de fontes para fundamentar as respostas

2. **Desenvolvimento de API**
   - API RESTful com FastAPI
   - Processamento assÃ­ncrono
   - ValidaÃ§Ã£o de entrada com pydantic
   - DocumentaÃ§Ã£o com OpenAPI/Swagger

3. **Funcionalidades AvanÃ§adas**
   - Busca hÃ­brida com grafos de conhecimento
   - Processamento multi-modal (imagens, tabelas)

4. **Monitoramento e Logging**
   - Logging estruturado
   - MÃ©tricas de performance
   - VerificaÃ§Ãµes de saÃºde da aplicaÃ§Ã£o

5. **Interface Web**
  - CriaÃ§Ã£o de pÃ¡gina da web para interagir com o sistema
  - Funcionalidade de ingestÃ£o, com inserÃ§Ã£o de domÃ­nio, palavras-chave e diretÃ³rio alvo
  - Sistema de configuraÃ§Ã£o personalizada
  - Funcionalidade de consulta

## Logging System

The system includes a robust logging system with the following features:

- JSON-formatted logs for machine readability
- Domain-based logging for different components
- Context tracking and correlation
- Error handling with stack traces
- Log file rotation and management
- Library log suppression
- Different formats for console and file output

### Log Levels

The system uses standard Python log levels:
- CRITICAL (50): Critical errors that may cause system failure
- ERROR (40): Errors that need attention but don't stop the system
- WARNING (30): Warning messages for potential issues
- INFO (20): General information about system operation
- DEBUG (10): Detailed information for debugging

### Log Format

Console output format:
```
2025-04-13T20:17:02.282109 - src.utils.logger - INFO - Sistema de registro de logs configurado
```

File output format (JSON):
```json
{
    "timestamp": "2025-04-13T20:17:02.282109",
    "level": "INFO",
    "name": "src.utils.logger",
    "message": "Sistema de registro de logs configurado",
    "function": "setup_logging",
    "context": {}
}
```

