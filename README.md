# Sistema RAG de IngestÃ£o de PDFs com GUI e testagem com consultas a LLMs

Sistema para processamento de documentos PDF em mÃºltiplos domÃ­nios de conhecimento, com geraÃ§Ã£o de embeddings, busca semÃ¢ntica, obtenÃ§Ã£o de respostas contextuais atravÃ©s de LLMs, e uma interface grÃ¡fica Streamlit para gerenciamento e consulta.

## VisÃ£o Geral

Este sistema implementa um pipeline RAG (Retrieval-Augmented Generation) para processar documentos PDF de um diretÃ³rio dentro de "domÃ­nios" de conhecimento especÃ­ficos. Para cada domÃ­nio ele cria um banco de dados e um Ã­ndice FAISS. Ele extrai o texto de cada documento, divide em chunks, gera embeddings vetoriais, e armazena os dados em bancos de dados SQLite e Ã­ndices vetoriais FAISS separados por domÃ­nio. Tanto um CLI quanto uma interface grÃ¡fica construÃ­da com Streamlit permitem ao usuÃ¡rio gerenciar esses domÃ­nios, iniciar a ingestÃ£o de documentos para um domÃ­nio selecionado, e realizar consultas que sÃ£o respondidas por um LLM (atravÃ©s da API da Hugging Face) com base no contexto recuperado do domÃ­nio apropriado.

### Funcionalidades Principais

- **Gerenciamento de DomÃ­nios:** CriaÃ§Ã£o, listagem, atualizaÃ§Ã£o e remoÃ§Ã£o de domÃ­nios de conhecimento isolados.
- **IngestÃ£o de Documentos por DomÃ­nio:** Processamento de diretÃ³rios de PDFs para um domÃ­nio especÃ­fico.
- **Pipeline RAG:**
    - ExtraÃ§Ã£o de texto de PDFs.
    - DetecÃ§Ã£o de duplicatas (intra-domÃ­nio) via hash MD5.
    - DivisÃ£o de texto em chunks semÃ¢nticos.
    - GeraÃ§Ã£o de embeddings (Sentence Transformers).
    - NormalizaÃ§Ã£o de texto.
    - Armazenamento de metadados e chunks (SQLite por domÃ­nio).
    - Armazenamento e busca vetorial de embeddings (FAISS por domÃ­nio).
- **Interface GrÃ¡fica (Streamlit):**
    - Gerenciamento de domÃ­nios.
    - Interface para ingestÃ£o de dados.
    - Interface de consulta para interagir com o LLM sobre domÃ­nios especÃ­ficos.
- **Consulta Contextual:**
    - Busca por similaridade no Ã­ndice FAISS do domÃ­nio selecionado.
    - RecuperaÃ§Ã£o de chunks relevantes.
    - IntegraÃ§Ã£o com LLM (Hugging Face API) para geraÃ§Ã£o de respostas baseadas no contexto recuperado.
- **Logging:** Sistema de log estruturado em JSON com rastreamento de contexto.
- **Testes:** Testes unitÃ¡rios e de integraÃ§Ã£o (Pytest) para garantir a funcionalidade dos componentes.

## Estrutura do Projeto

```plaintext
/
â”œâ”€â”€ .streamlit/
â”‚   â””â”€â”€ config.toml
â”œâ”€â”€ gui/
â”‚   â””â”€â”€ streamlit_utils.toml       # FunÃ§Ãµes auxiliares do GUI
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ app.log           # Logs da aplicaÃ§Ã£o em arquivo
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ 1_Domain_Management.py
â”‚   â”œâ”€â”€ 2_Data_Ingestion.py
â”‚   â”œâ”€â”€ 3_Query_Interface.py
â”‚   â””â”€â”€ 4_Configuration.py # (Placeholder/Em desenvolvimento)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ config_manager.py
â”‚   â”‚   â”œâ”€â”€ config_utils.py
â”‚   â”‚   â”œâ”€â”€ models.py       # Modelos das configuraÃ§Ãµes
â”‚   â”œâ”€â”€ data_ingestion/     # LÃ³gica de ingestÃ£o de documentos
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ data_ingestion_orchestrator.py
â”‚   â”‚   â”œâ”€â”€ document_processor.py
â”‚   â”‚   â””â”€â”€ chunking_strategy/  # EstratÃ©gias de chunk e seu gerenciador
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ chunking_manager.py
â”‚   â”‚       â”œâ”€â”€ chunking_strategy.py   # Abstract class
â”‚   â”‚       â”œâ”€â”€ recursive_strategy.py
â”‚   â”‚       â””â”€â”€ semantic_cluster_strategy.py
â”‚   â”œâ”€â”€ models/             # Modelos Pydantic para estruturas de dados
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ chunk.py
â”‚   â”‚   â”œâ”€â”€ document_file.py
â”‚   â”‚   â”œâ”€â”€ domain.py
â”‚   â”‚   â””â”€â”€ domain_config.py
â”‚   â”œâ”€â”€ query_processing/   # LÃ³gica de consulta e interaÃ§Ã£o com LLM
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ hugging_face_manager.py
â”‚   â”‚   â””â”€â”€ query_orchestrator.py
â”‚   â”œâ”€â”€ utils/              # UtilitÃ¡rios compartilhados
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ domain_manager.py
â”‚   â”‚   â”œâ”€â”€ embedding_generator.py
â”‚   â”‚   â”œâ”€â”€ faiss_manager.py
â”‚   â”‚   â”œâ”€â”€ logger.py
â”‚   â”‚   â”œâ”€â”€ sqlite_manager.py
â”‚   â”‚   â””â”€â”€ text_normalizer.py
â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ control.db      # Banco de dados de controle (registros de domÃ­nio)
â”‚   â”œâ”€â”€ domains/            # Armazenamento de dados por domÃ­nio
â”‚   â”‚   â””â”€â”€ [domain_name]/  # DiretÃ³rio para cada domÃ­nio criado
â”‚   â”‚       â”œâ”€â”€ [domain_name].db
â”‚   â”‚       â””â”€â”€ vector_store/
â”‚   â”‚           â””â”€â”€ [domain_name].faiss
â”‚   â””â”€â”€ schemas/            # Schemas SQL para bancos de dados
â”‚       â”œâ”€â”€ control_schema.sql
â”‚       â””â”€â”€ schema.sql
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ test_config_manager.py/
â”‚   â”œâ”€â”€ data_ingestion/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ test_data_ingestion_orchestrator.py
â”‚   â”‚   â”œâ”€â”€ test_document_processor.py
â”‚   â”‚   â””â”€â”€ test_docs/
â”‚   â”‚       â””â”€â”€ generate_test_pdfs.py # (Script auxiliar para testes)
â”‚   â”œâ”€â”€ query_processing/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ test_hugging_face_manager.py
â”‚   â”‚   â””â”€â”€ test_query_orchestrator.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ test_domain_manager.py
â”‚   â”‚   â”œâ”€â”€ test_embedding_generator.py
â”‚   â”‚   â”œâ”€â”€ test_faiss_manager.py
â”‚   â”‚   â”œâ”€â”€ test_logger.py
â”‚   â”‚   â”œâ”€â”€ test_sqlite_manager.py
â”‚   â”‚   â””â”€â”€ test_text_normalizer.py
â”‚   â””â”€â”€ conftest.py         # ConfiguraÃ§Ãµes e fixtures para Pytest
â”œâ”€â”€ Admin.py                # Ponto de entrada principal da GUI Streamlit
â”œâ”€â”€ main.py                 # Ponto de entrada principal da CLI (Incompleto)
â”œâ”€â”€ README.md               
â”œâ”€â”€ requirements.txt        
â”œâ”€â”€ .env     
â”œâ”€â”€ install.py             # Script de instalaÃ§Ã£o do programa                    
â””â”€â”€ .gitignore              
```

## Componentes Principais

### OrquestraÃ§Ã£o e Gerenciamento

-   **`ConfigManager` (`src/config/config_manager.py`):** Gerencia o carregamento, validaÃ§Ã£o, salvamento, backup e reset das configuraÃ§Ãµes da aplicaÃ§Ã£o (arquivo `config.toml`).
-   **`DomainManager` (`src/utils/domain_manager.py`):** ResponsÃ¡vel por gerenciar os domÃ­nios de conhecimento (criar, listar, atualizar, deletar) e seus respectivos arquivos (banco de dados, Ã­ndice vetorial).
-   **`ChunkingManager` (`src/data_ingestion/chunking_strategy/chunking_manager.py`):** Gerencia diferentes estratÃ©gias de chunking. Inicializa e delega para uma estratÃ©gia especÃ­fica (ex. Recursive, SemanticCluster) de acordo com as definiÃ§Ãµes de configuraÃ§Ã£o.
-   **`DataIngestionOrchestrator` (`src/data_ingestion/data_ingestion_orchestrator.py`):** Coordena o pipeline completo de ingestÃ£o de documentos para um domÃ­nio especÃ­fico, desde a leitura do PDF atÃ© o armazenamento dos chunks e embeddings.
-   **`QueryOrchestrator` (`src/query_processing/query_orchestrator.py`):** Gerencia o fluxo de consulta, incluindo a geraÃ§Ã£o de embedding da query, busca no Ã­ndice vetorial, recuperaÃ§Ã£o de chunks, formataÃ§Ã£o do prompt e interaÃ§Ã£o com o LLM.

### Gerenciamento de Dados e Vetores

-   **`SQLiteManager` (`src/utils/sqlite_manager.py`):** Interface para os bancos de dados SQLite. Gerencia um banco de controle (`control.db`) para os registros de domÃ­nio e bancos de dados especÃ­ficos para cada domÃ­nio, armazenando metadados de documentos e chunks.
-   **`FaissManager` (`src/utils/faiss_manager.py`):** Interface para os Ã­ndices vetoriais FAISS. Gerencia a criaÃ§Ã£o, carregamento, adiÃ§Ã£o de embeddings e busca por similaridade dentro do Ã­ndice FAISS de cada domÃ­nio.

### Processamento de Documentos e Texto

-   **`DocumentProcessor` (`src/data_ingestion/document_processor.py`):** Extrai texto de arquivos PDF e calcula hashes para detecÃ§Ã£o de duplicatas.
-   **`Chunking Strategies` (`src/data_ingestion/chunking_strategy/`):**
    -   **`RecursiveStrategy` (`recursive_strategy.py`):** Realiza chunking por divisÃ£o recursiva de caracteres chave.
    -   **`SemanticClusterStrategy` (`semantic_cluster_strategy.py`):** Realiza chunking por clusterizaÃ§Ã£o semÃ¢ntica de segmentos de texto. contextually coherent chunks.
-   **`TextNormalizer` (`src/utils/text_normalizer.py`):** Aplica normalizaÃ§Ã£o ao texto (e.g., Unicode, lowercase) para consistÃªncia.
-   **`EmbeddingGenerator` (`src/utils/embedding_generator.py`):** Gera embeddings vetoriais para os chunks de texto usando modelos da biblioteca `sentence-transformers`.

### InteraÃ§Ã£o com LLM

-   **`HuggingFaceManager` (`src/query_processing/hugging_face_manager.py`):** Interage com a API de InferÃªncia da Hugging Face para enviar prompts formatados (incluindo o contexto recuperado) e obter respostas do modelo de linguagem.

### Interface GrÃ¡fica (GUI)

-   **`Admin.py` e `pages/`:** AplicaÃ§Ã£o Streamlit que fornece a interface para gerenciamento de domÃ­nios, ingestÃ£o de dados e consulta ao sistema RAG.

### Modelos de Dados

-   **`src/models/`:** ContÃ©m as definiÃ§Ãµes (usando Pydantic) para as estruturas de dados `Domain`, `DomainConfig`, `DocumentFile`, e `Chunk`.

## Requisitos

- Python 3.10+
- Git (para clonar o repositÃ³rio)
- DependÃªncias principais:
  * streamlit
  * pydantic
  * pypdf 5.4.0
  * sentence-transformers 3.4.1
  * faiss-cpu 1.10.0
  * huggingface-hub 0.29.3
  * langchain 0.3.21 # DependÃªncia pode ser indireta via langchain-text-splitters
  * langchain-text-splitters 0.3.7
  * SQLAlchemy 2.0.39
  * pytest 8.3.5
  * python-dotenv 1.0.1

## InstalaÃ§Ã£o

1.  **Clone o repositÃ³rio:**
    ```bash
    git clone https://github.com/fmossri/pbic-project.git
    cd pbic-project
    ```

2.  **Crie e ative um ambiente virtual:** (Recomendado)
    ```bash
    # Linux/macOS
    python3 -m venv .venv
    source .venv/bin/activate

    # Windows (cmd/powershell)
    python -m venv .venv
    .venv\Scripts\activate
    ```

3.  **Instale as dependÃªncias:**
    ```bash
    python install * Substitui pip install -r requirements.txt, para garantir portabilidade atravÃ©s de sistemas com gpus diferentes, ou sem gpu
    ```

4.  **Configure o Token da Hugging Face:**
    *   Crie um token de acesso com permissÃµes de leitura no site da [Hugging Face](https://huggingface.co/settings/tokens).
    *   Crie um arquivo chamado `.env` na raiz do projeto.
    *   Adicione a seguinte linha ao arquivo `.env`, substituindo `seu-token-aqui` pelo seu token:
        ```dotenv
        HUGGINGFACE_API_TOKEN="seu-token-aqui"
        ```
    ***As configuraÃ§Ãµes de token podem mudar de acordo com o modelo escolhido. acessar pÃ¡gina da Hugging Face para mais detalhes.

## Uso

### Via GUI

### Iniciando a Interface GrÃ¡fica

```bash
streamlit run Admin.py
```

### Via CLI (Temporariamente indisponÃ­vel)

** main.py --help (Incompleto)

#### Adicionando DomÃ­nios
```bash
python main.py -d "nome do domÃ­nio", "breve descriÃ§Ã£o", "palavras-chave" [--debug]
```

#### Processando PDFs e Gerando Embeddings

```bash
python main.py -i caminho/do/diretÃ³rio [--debug]
```

#### Realizando Consultas

```bash
python main.py -q "Sua pergunta aqui" [--debug]
```

#### Executando Testes

```bash
python -m pytest
```

## Estado Atual do Desenvolvimento

### Em Desenvolvimento ğŸ”„

1. **Benchmarking**
    - Pesquisar estratÃ©gias de avaliaÃ§Ã£o de sistemas RAG 
    - Implementar testagem e coleta de mÃ©tricas relevantes no sistema.

2. **Novos Testes de Chunking**
    - Criar casos de teste para ChunkingManager, RecursiveStrategy e SemanticClusterStrategy

## PrÃ³ximos Passos ğŸš€

1.  **IntegraÃ§Ã£o de OCR:**
    - Adicionar capacidade de OCR (Optical Character Recognition) Ã  lÃ³gica de extraÃ§Ã£o de conteÃºdo de PDFs, permitindo processar documentos baseados em imagem.

2.  **AvaliaÃ§Ã£o de Modelos:**
    - Avaliar o desempenho e a adequaÃ§Ã£o de diferentes modelos de embedding e LLMs para as tarefas especÃ­ficas da aplicaÃ§Ã£o.

3. **RemoÃ§Ã£o de Arquivos de um DomÃ­nio**
    - Implementar remoÃ§Ã£o de um arquivo do domÃ­nio. A lÃ³gica para a remoÃ§Ã£o do arquivo e seus chunks do banco de dados jÃ¡ existe; Desenvolver lÃ³gica de remoÃ§Ã£o dos embeddings associados ao documento do Ã­ndice Faiss.

### PossÃ­veis Melhorias ğŸ’¡

   **Aprimoramento do Sistema de ConfiguraÃ§Ã£o**
    - Criar sistema de configuraÃ§Ã£o via CLI

   **Aprimoramento do Sistema de Consulta**
   - OtimizaÃ§Ã£o de prompts
   - ExpansÃ£o de consultas usando sinÃ´nimos
   - Re-ranqueamento dos chunks recuperados
   - AtribuiÃ§Ã£o de fontes para fundamentar as respostas

   **ExpansÃ£o de Funcionalidades**
   - Adicionar suporte a outros tipos de documentos (e.g., .docx, .txt).
   - Implementar seleÃ§Ã£o de modelos de embedding e LLMs atravÃ©s da configuraÃ§Ã£o.
   - Explorar outras estratÃ©gias avanÃ§adas de chunking e recuperaÃ§Ã£o.
   - Implementar outras opÃ§Ãµes de normalizaÃ§Ã£o e tratamento de texto.

   **Funcionalidades AvanÃ§adas**
   - Busca hÃ­brida com grafos de conhecimento
   - Processamento multi-modal (imagens, tabelas)
   - Uso de GPU (cuda)
   - Processamento paralelo

   **SaÃºde da AplicaÃ§Ã£o**
   - Otimizar performance e escalabilidade.
   - Implementar verificaÃ§Ãµes de saÃºde da aplicaÃ§Ã£o.
   - Limpar e padronizar logging e coleta de mÃ©tricas.
   - Melhorar tratamento de erros e resiliÃªncia.

## Problemas Conhecidos

- **Erro do File Watcher do Streamlit com PyTorch:** Ao navegar para a pÃ¡gina `Gerenciamento de DomÃ­nios`, um erro `RuntimeError: Tried to instantiate class '__path__._path'...` relacionado a `torch.classes` pode aparecer no console. Isso parece ser um problema com o file watcher do Streamlit tentando inspecionar a biblioteca `torch`. Tentativas de solucionar isso adicionando `torch` ou `.venv` Ã  `folderWatchBlacklist` ou definindo `watchFileSystem = false` no arquivo `.streamlit/config.toml` nÃ£o surtiram efeito. O erro parece ser apenas um ruÃ­do no console e nÃ£o afeta a funcionalidade principal da GUI no momento. **Workaround: Silenciar Watcher em `.streamlit/config.toml` com `fileWatcherType = "none"`. PorÃ©m, ao modificarmos o cÃ³digo, necessitamos atualizar a pÃ¡gina ou reiniciar o streamlit.

- **VisualizaÃ§Ã£o das configuraÃ§Ãµes, em Configuration** A pÃ¡gina `4_Configuration.py` mostra todas as propriedades da configuraÃ§Ã£o atual, a partir da leitura do arquivo `config.toml`. PorÃ©m, apÃ³s atualizaÃ§Ã£o do cÃ³digo, as definiÃ§Ãµes de configuraÃ§Ã£o relativas Ã  Chunking, modelo de embedding, Ã­ndice faiss e normalizaÃ§Ã£o de Embeddings foram passadas Ã  Ã¡rea de criaÃ§Ã£o de DomÃ­nio (Dado que essas configuraÃ§Ãµes nÃ£o podem ser mudadas apÃ³s definidas, pois levam Ã  inconsistÃªncia dos dados armazenados e potencialmente corrupÃ§Ã£o dos registros). Como a criaÃ§Ã£o de um novo domÃ­nio nÃ£o gera chamada Ã  `ConfigManager.save_config()`, a exibiÃ§Ã£o dos valores desses campos de configuraÃ§Ã£o se torna incorreta. **Fix: Ou salvar o arquivo a cada novo domÃ­nio selecionado em DataIngestion (O que parece nÃ£o ser desejÃ¡vel; o arquivo nÃ£o deve ser alterado repetidamente); ou mover essas informaÃ§Ãµes da seÃ§Ã£o `ConfiguraÃ§Ã£o Atual` para a seÃ§Ã£o `Detalhes do DomÃ­nio`; ou fazer uma busca dessas informaÃ§Ãµes no domÃ­nio armazenado na `session state`; ou dividir a seÃ§Ã£o em duas: ConfiguraÃ§Ãµes gerais e configuraÃ§Ãµes do domÃ­nio.

- **Caracteres especiais do PT-BR sendo passados para o JSON no logger** As mensagens de log com caractÃ©res do PortuguÃªs, como Ã¢, Ã£, Ã§, etc., estÃ£o sendo passadas para o parsing JSON diretamente, sem tratamento. Como JSON nÃ£o lida com esse tipo de caractÃ©re, as mensagens logadas se tornam defeituosas. **Fix: Criar uma funÃ§Ã£o de tratamento de string que remova os caracteres especiais, e passar as mensagens atravÃ©s dela antes de enviar para o handler de arquivo.